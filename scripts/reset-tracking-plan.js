const fs = require('fs');
const path = require('path');
const axios = require('axios');

const planDir = process.env.PLAN_DIR;
const trackingPlanId = process.env.SEGMENT_TRACKING_PLAN_ID;
const apiKey = process.env.SEGMENT_API_KEY;
const baseUrl = `https://api.segmentapis.com/tracking-plans/${trackingPlanId}`;
const paginationCount = 200;

console.log(`ğŸ“ Using PLAN_DIR: ${planDir}`);
console.log(`ğŸ†” Tracking Plan ID: ${trackingPlanId}`);

async function fetchAllRules(cursor = null, accumulatedRules = []) {
  const params = new URLSearchParams({ 'pagination[count]': paginationCount.toString() });
  if (cursor) params.append('pagination[cursor]', cursor);

  const url = `${baseUrl}/rules?${params}`;
  console.log(`ğŸ” Fetching: ${url}`);

  try {
    const response = await axios.get(url, {
      headers: {
        Authorization: `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
    });

    const rules = response.data.data.rules || [];
    const pagination = response.data.data.pagination;
    accumulatedRules.push(...rules);

    console.log(`ğŸ“„ Fetched ${rules.length} rules (total so far: ${accumulatedRules.length})`);

    if (pagination?.next) {
      return fetchAllRules(pagination.next, accumulatedRules);
    } else {
      return accumulatedRules;
    }
  } catch (error) {
    console.error('âŒ Error fetching rules:', error.response?.data || error.message);
    return accumulatedRules;
  }
}

async function deleteRulesInBatches(rules) {
  const chunkSize = 200;
  console.log(`ğŸ§¹ Deleting ${rules.length} rules in batches of ${chunkSize}`);

  for (let i = 0; i < rules.length; i += chunkSize) {
    const chunk = rules.slice(i, i + chunkSize).map(r => ({
      key: r.key,
      type: r.type,
      version: r.version,
    }));

    console.log(`ğŸ—‘ï¸ Deleting batch ${i / chunkSize + 1}, size: ${chunk.length}`);

    try {
      await axios.delete(`${baseUrl}/rules`, {
        headers: {
          Authorization: `Bearer ${apiKey}`,
          'Content-Type': 'application/json',
        },
        data: { rules: chunk },
      });
      console.log(`âœ… Deleted ${chunk.length} rules`);
    } catch (error) {
      console.error(`âŒ Error deleting batch ${i / chunkSize + 1}:`, error.response?.data || error.message);
    }
  }
}

async function uploadProdChunks() {
  console.log(`ğŸ“ Checking directory: ${planDir}`);
  const files = fs.readdirSync(planDir)
    .filter(f => f.startsWith('current-rules') && f.endsWith('.json'))
    .sort();

  console.log(`ğŸ“¦ Found ${files.length} rule file(s): ${files.join(', ')}`);

  for (const file of files) {
    const filePath = path.join(planDir, file);
    console.log(`ğŸ“¤ Reading file: ${filePath}`);

    const content = JSON.parse(fs.readFileSync(filePath, 'utf-8'));
    const rules = content.rules;

    if (!Array.isArray(rules) || rules.length === 0) {
      console.warn(`âš ï¸ No rules found in ${file}. Skipping.`);
      continue;
    }

    const chunkSize = 200;
    for (let i = 0; i < rules.length; i += chunkSize) {
      const chunk = rules.slice(i, i + chunkSize);
      console.log(`ğŸš€ Uploading ${chunk.length} rules from ${file} (chunk ${i / chunkSize + 1})`);

      try {
        const res = await axios.patch(`${baseUrl}/rules`, { rules: chunk }, {
          headers: {
            Authorization: `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
          },
        });

        console.log(`âœ… Uploaded chunk ${i / chunkSize + 1} from ${file}. Response:`, res.status);
      } catch (error) {
        console.error(`âŒ Failed to upload chunk ${i / chunkSize + 1} from ${file}:`, error.response?.data || error.message);
      }
    }
  }
}

async function main() {
  console.log(`ğŸš¨ Resetting tracking plan: ${trackingPlanId}`);

  const existingRules = await fetchAllRules();
  console.log(`ğŸ“¦ Found ${existingRules.length} rules to delete`);

  if (existingRules.length > 0) {
    await deleteRulesInBatches(existingRules);
  } else {
    console.log('ğŸ“­ No rules to delete.');
  }

  console.log(`ğŸ§ª Resolved directory path: ${planDir}`);
  console.log(`ğŸ“„ Directory contents: ${fs.existsSync(planDir) ? fs.readdirSync(planDir).join(', ') : 'Directory does not exist'}`);
  console.log('ğŸ“¤ Uploading production rules...');
  await uploadProdChunks();

  console.log('ğŸ‰ Tracking plan reset complete.');
}

main();

